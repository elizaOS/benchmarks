# RLM Benchmark Report

Generated: 2026-02-14 20:19:23

## Summary

- Overall accuracy: 0.0% (0/18 tasks)
- S-NIAH by length: 10K: 0.0%, 1K: 0.0%
- Total cost: $0.0000, Avg: $0.000000/task

### Key Metrics

| Metric | Value |
|--------|-------|
| Total Tasks | 18 |
| Passed | 0 |
| Overall Accuracy | 0.0% |
| Avg Semantic Similarity | 0.000 |
| Total Cost (USD) | $0.0000 |
| Avg Latency (ms) | 57.6 |
| Avg Iterations | 0.0 |
| Avg Depth | 0.0 |

## S-NIAH Results (Paper Table 1)

Accuracy by context length:

| Model | 1K | 10K | 100K | 1M | 10M | 100M |
|-------|-------|-------|-------|-------|-------|-------|
| This Run | - | - | - | - | - | - |
| RLM (Gemini 2.0 Flash) | 100.0% | 100.0% | 98.0% | - | - | - |
| Gemini 2.0 Flash (direct) | 100.0% | 98.0% | 85.0% | - | - | - |
| GPT-5 (direct) | 100.0% | 99.0% | 92.0% | - | - | - |

## Cost Analysis (Paper Figure 3)

| Metric | Value |
|--------|-------|
| Total Cost | $0.0000 |
| Avg Cost/Task | $0.000000 |
| Cost/1K Tokens | $0.000000 |
| Accuracy/Dollar | 0.00 |

## Paper Comparison

Comparison of this benchmark run with published results from arXiv:2512.24601.

### S-NIAH

This run results:
- 1K: 0.0%
- 10K: 0.0%

See the paper for detailed methodology and comparison.

