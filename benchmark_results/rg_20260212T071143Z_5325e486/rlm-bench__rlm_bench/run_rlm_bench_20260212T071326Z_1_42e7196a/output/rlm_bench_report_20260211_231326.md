# RLM Benchmark Report

Generated: 2026-02-11 23:13:26

## Summary

- Overall accuracy: 25.9% (21/81 tasks)
- S-NIAH by length: 100K: 20.0%, 10K: 33.3%, 1K: 26.7%
- OOLONG accuracy: 100.0%, OOLONG-Pairs: 0.0%
- Most used strategies: peek, grep
- Total cost: $3.0043, Avg: $0.037090/task

### Key Metrics

| Metric | Value |
|--------|-------|
| Total Tasks | 81 |
| Passed | 21 |
| Overall Accuracy | 25.9% |
| Avg Semantic Similarity | 0.278 |
| Total Cost (USD) | $3.0043 |
| Avg Latency (ms) | 2.6 |
| Avg Iterations | 4.0 |
| Avg Depth | 1.3 |

## S-NIAH Results (Paper Table 1)

Accuracy by context length:

| Model | 1K | 10K | 100K | 1M | 10M | 100M |
|-------|-------|-------|-------|-------|-------|-------|
| This Run | 26.7% | 33.3% | 20.0% | - | - | - |
| RLM (Gemini 2.0 Flash) | 100.0% | 100.0% | 98.0% | - | - | - |
| Gemini 2.0 Flash (direct) | 100.0% | 98.0% | 85.0% | - | - | - |
| GPT-5 (direct) | 100.0% | 99.0% | 92.0% | - | - | - |

## OOLONG Results (Paper Table 2)

| Model | Retrieval | Pairs |
|-------|-----------|-------|
| This Run | 100.0% | 0.0% |
| RLM (Gemini 2.0 Flash) | 85.0% | 72.0% |
| Gemini 2.0 Flash (direct) | 65.0% | 52.0% |

## Strategy Analysis (Paper Section 4.1)

RLM uses various strategies to process long contexts:

| Strategy | Usage Count | Success Rate | Avg Latency (ms) |
|----------|-------------|--------------|------------------|
| peek | 81 | 25.9% | 2.6 |
| grep | 81 | 25.9% | 2.6 |

### Strategy Definitions

- **peek**: Examining prefix/suffix of context (e.g., `prompt[:100]`)
- **grep**: Using regex to filter relevant portions
- **chunk**: Splitting context for parallel processing
- **stitch**: Combining sub-call results
- **subcall**: Recursive self-call to process sub-contexts

## Cost Analysis (Paper Figure 3)

| Metric | Value |
|--------|-------|
| Total Cost | $3.0043 |
| Avg Cost/Task | $0.037090 |
| Cost/1K Tokens | $0.000999 |
| Accuracy/Dollar | 0.09 |

## Paper Comparison

Comparison of this benchmark run with published results from arXiv:2512.24601.

### S-NIAH

This run results:
- 1K: 26.7%
- 10K: 33.3%
- 100K: 20.0%

### OOLONG

This run results:
- oolong_retrieval: 100.0%
- oolong_pairs: 0.0%

See the paper for detailed methodology and comparison.

