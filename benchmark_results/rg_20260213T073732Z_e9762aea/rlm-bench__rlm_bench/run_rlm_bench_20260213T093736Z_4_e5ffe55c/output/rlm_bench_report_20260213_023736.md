# RLM Benchmark Report

Generated: 2026-02-13 02:37:36

## Summary

- Overall accuracy: 19.8% (16/81 tasks)
- S-NIAH by length: 100K: 13.3%, 10K: 20.0%, 1K: 13.3%
- OOLONG accuracy: 100.0%, OOLONG-Pairs: 0.0%
- Most used strategies: peek, grep
- Total cost: $3.0043, Avg: $0.037090/task

### Key Metrics

| Metric | Value |
|--------|-------|
| Total Tasks | 81 |
| Passed | 16 |
| Overall Accuracy | 19.8% |
| Avg Semantic Similarity | 0.216 |
| Total Cost (USD) | $3.0043 |
| Avg Latency (ms) | 2.7 |
| Avg Iterations | 4.0 |
| Avg Depth | 1.3 |

## S-NIAH Results (Paper Table 1)

Accuracy by context length:

| Model | 1K | 10K | 100K | 1M | 10M | 100M |
|-------|-------|-------|-------|-------|-------|-------|
| This Run | 13.3% | 20.0% | 13.3% | - | - | - |
| RLM (Gemini 2.0 Flash) | 100.0% | 100.0% | 98.0% | - | - | - |
| Gemini 2.0 Flash (direct) | 100.0% | 98.0% | 85.0% | - | - | - |
| GPT-5 (direct) | 100.0% | 99.0% | 92.0% | - | - | - |

## OOLONG Results (Paper Table 2)

| Model | Retrieval | Pairs |
|-------|-----------|-------|
| This Run | 100.0% | 0.0% |
| RLM (Gemini 2.0 Flash) | 85.0% | 72.0% |
| Gemini 2.0 Flash (direct) | 65.0% | 52.0% |

## Strategy Analysis (Paper Section 4.1)

RLM uses various strategies to process long contexts:

| Strategy | Usage Count | Success Rate | Avg Latency (ms) |
|----------|-------------|--------------|------------------|
| peek | 81 | 19.8% | 2.7 |
| grep | 81 | 19.8% | 2.7 |

### Strategy Definitions

- **peek**: Examining prefix/suffix of context (e.g., `prompt[:100]`)
- **grep**: Using regex to filter relevant portions
- **chunk**: Splitting context for parallel processing
- **stitch**: Combining sub-call results
- **subcall**: Recursive self-call to process sub-contexts

## Cost Analysis (Paper Figure 3)

| Metric | Value |
|--------|-------|
| Total Cost | $3.0043 |
| Avg Cost/Task | $0.037090 |
| Cost/1K Tokens | $0.000999 |
| Accuracy/Dollar | 0.07 |

## Paper Comparison

Comparison of this benchmark run with published results from arXiv:2512.24601.

### S-NIAH

This run results:
- 1K: 13.3%
- 10K: 20.0%
- 100K: 13.3%

### OOLONG

This run results:
- oolong_retrieval: 100.0%
- oolong_pairs: 0.0%

See the paper for detailed methodology and comparison.

